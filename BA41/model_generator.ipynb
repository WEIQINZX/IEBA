{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF\n",
    "## RF-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集,mobile-phone-train.csv\n",
    "data = pd.read_csv('mobile-phone-train.csv',index_col=0)\n",
    "#data.iloc[:,:-1]\n",
    "X, y = data.iloc[:,:-1], data['price_range']\n",
    "# 对y进行label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray编码转换函数\n",
    "def gray_encode(value, bits):\n",
    "    \"\"\" 将十进制数值转换为Gray编码的二进制字符串 \"\"\"\n",
    "    binary = bin(value)[2:].zfill(bits)  # 转换为二进制字符串并补齐\n",
    "    gray = binary[0]  # Gray编码的第一位与二进制相同\n",
    "    for i in range(1, len(binary)):\n",
    "        gray += str(int(binary[i]) ^ int(binary[i-1]))  # 计算Gray编码\n",
    "    return gray\n",
    "\n",
    "def gray_decode(gray):\n",
    "    # 将输入的列表转换为字符串形式\n",
    "    gray_string = ''.join(map(str, gray))\n",
    "    \n",
    "    # 初始化二进制字符串\n",
    "    binary_string = gray_string[0]  # 第一位相同\n",
    "\n",
    "    # 解码过程\n",
    "    for i in range(1, len(gray_string)):\n",
    "        # 当前二进制位为前一位二进制位与当前Gray位的异或\n",
    "        binary_value = int(binary_string[i-1]) ^ int(gray_string[i])\n",
    "        binary_string += str(binary_value)\n",
    "\n",
    "    # 将二进制字符串转换为十进制数\n",
    "    decimal_value = int(binary_string, 2)\n",
    "    return decimal_value\n",
    "\n",
    "# 计算十进制数字对应的Gray编码位数\n",
    "def gray_bits(value):\n",
    "    return len(bin(value)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weiqin/Library/Python/3.11/lib/python/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/weiqin/Library/Python/3.11/lib/python/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# 设置遗传算法的个体和种群\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))  # 最大化适应度\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# 设置编码位数\n",
    "N_ESTIMATORS_BITS = gray_bits(500)  # n_estimators 最大值为 500\n",
    "MAX_DEPTH_BITS = gray_bits(50)  # max_depth 最大值为 50\n",
    "MIN_SAMPLES_SPLIT_BITS = gray_bits(10)  # min_samples_split 最大值为 20\n",
    "MAX_FEATURES_BITS = gray_bits(15)  # max_features 最大值为15\n",
    "\n",
    "# 计算总位数\n",
    "TOTAL_BITS = N_ESTIMATORS_BITS + MAX_DEPTH_BITS + MIN_SAMPLES_SPLIT_BITS + MAX_FEATURES_BITS\n",
    "\n",
    "# 定义空dataframe存储计算过的个体参数及其fitness\n",
    "df = pd.DataFrame(columns=['n_estimators', 'max_depth', 'min_samples_split', 'max_features', 'fitness'])\n",
    "\n",
    "# 定义适应度函数\n",
    "def evaluate_rf(individual):\n",
    "    # 将individual转换为一整个str，作为dataframe的index\n",
    "    index_str = ''.join(map(str, individual))\n",
    "\n",
    "    # 检查是否已经计算过\n",
    "    if index_str in df.index:\n",
    "        return (df.loc[index_str, 'fitness'],)\n",
    "    \n",
    "    n_estimators = gray_decode(individual[0:9])  # 解码n_estimators（9位编码）\n",
    "    max_depth = gray_decode(individual[9:15])  # 解码max_depth（6位编码）\n",
    "    min_samples_split = gray_decode(individual[15:19])  # 解码min_samples_split（4位编码）\n",
    "    max_features = gray_decode(individual[19:23]) #/ X.shape[1]  # 解码max_features（5位编码，归一化）\n",
    "\n",
    "    # 参数合法性检查，将非法参数转换为合理范围\n",
    "    n_estimators = max(1, int(n_estimators))  # 保证 n_estimators 至少为 1\n",
    "    max_depth = int(max_depth) if max_depth > 0 else None  # 保证 max_depth 大于 0 或为 None\n",
    "    min_samples_split = max(2, int(min_samples_split))  # 最小分裂样本数不能小于 2\n",
    "    \n",
    "    # max_features 校正，确保为有效值\n",
    "    if max_features <= 0:\n",
    "        max_features = None  # 默认使用所有特征\n",
    "    elif max_features <= 1:\n",
    "        max_features = float(max_features)  # 如果 max_features 小于等于 1，作为比例处理\n",
    "    else:\n",
    "        max_features = min(int(max_features),X.shape[1])  # 否则作为整数处理\n",
    "\n",
    "    # 定义 RandomForestClassifier 模型\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        max_features=max_features,  # 调整后的 max_features\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 得分为模型的交叉验证准确率\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "    # 保存计算结果\n",
    "    df.loc[index_str] = [n_estimators, max_depth, min_samples_split, max_features, np.mean(scores)]\n",
    "\n",
    "    return (np.mean(scores),)\n",
    "\n",
    "def generate_gray_individual():\n",
    "    return [random.randint(0, 1) for _ in range(TOTAL_BITS)]\n",
    "\n",
    "# 注册超参数生成器\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, generate_gray_individual)\n",
    "#toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 #lambda: [random.choice(['0', '1']) for _ in range(TOTAL_BITS)],n=1)  # 使用随机生成的二进制字符串\n",
    "\n",
    "# 创建种群\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# 注册操作\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)  # 交叉操作\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.15)  # 变异操作\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # 选择操作\n",
    "toolbox.register(\"evaluate\", evaluate_rf)  # 适应度评估\n",
    "\n",
    "# 进化参数设置，设置random seed\n",
    "np.random.seed(42)\n",
    "population = toolbox.population(n=50)  # 种群数量\n",
    "NGEN = 100  # 迭代次数\n",
    "CXPB = 0.5  # 交叉概率\n",
    "MUTPB = 0.15  # 变异概率\n",
    "ELITE_SIZE = 5  # 精英个体数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "Generation 2\n",
      "Generation 3\n",
      "Generation 4\n",
      "Generation 5\n",
      "Generation 6\n",
      "Generation 7\n",
      "Generation 8\n",
      "Generation 9\n",
      "Generation 10\n",
      "Generation 11\n",
      "Generation 12\n",
      "Generation 13\n",
      "Generation 14\n",
      "Generation 15\n",
      "Generation 16\n",
      "Generation 17\n",
      "Generation 18\n",
      "Generation 19\n",
      "Generation 20\n",
      "Generation 21\n",
      "Generation 22\n",
      "Generation 23\n",
      "Generation 24\n",
      "Generation 25\n",
      "Generation 26\n",
      "Generation 27\n",
      "Generation 28\n",
      "Generation 29\n",
      "Generation 30\n",
      "Generation 31\n",
      "Generation 32\n",
      "Generation 33\n",
      "Generation 34\n",
      "Generation 35\n",
      "Generation 36\n",
      "Generation 37\n",
      "Generation 38\n",
      "Generation 39\n",
      "Generation 40\n",
      "Generation 41\n",
      "Generation 42\n",
      "Generation 43\n",
      "Generation 44\n",
      "Generation 45\n",
      "Generation 46\n",
      "Generation 47\n",
      "Generation 48\n",
      "Generation 49\n",
      "Generation 50\n",
      "Generation 51\n",
      "Generation 52\n",
      "Generation 53\n",
      "Generation 54\n",
      "Generation 55\n",
      "Generation 56\n",
      "Generation 57\n",
      "Generation 58\n",
      "Generation 59\n",
      "Generation 60\n",
      "Generation 61\n",
      "Generation 62\n",
      "Generation 63\n",
      "Generation 64\n",
      "Generation 65\n",
      "Generation 66\n",
      "Generation 67\n",
      "Generation 68\n",
      "Generation 69\n",
      "Generation 70\n",
      "Generation 71\n",
      "Generation 72\n",
      "Generation 73\n",
      "Generation 74\n",
      "Generation 75\n",
      "Generation 76\n",
      "Generation 77\n",
      "Generation 78\n",
      "Generation 79\n",
      "Generation 80\n",
      "Generation 81\n",
      "Generation 82\n",
      "Generation 83\n",
      "Generation 84\n",
      "Generation 85\n",
      "Generation 86\n",
      "Generation 87\n",
      "Generation 88\n",
      "Generation 89\n",
      "Generation 90\n",
      "Generation 91\n",
      "Generation 92\n",
      "Generation 93\n",
      "Generation 94\n",
      "Generation 95\n",
      "Generation 96\n",
      "Generation 97\n",
      "Generation 98\n",
      "Generation 99\n",
      "Generation 100\n",
      "Best individual is [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0], with fitness (0.8916666666666666,)\n"
     ]
    }
   ],
   "source": [
    "# 执行遗传算法优化,并绘制适应度曲线\n",
    "fitnesses_plot = []\n",
    "for gen in range(NGEN):\n",
    "    print(f\"Generation {gen+1}\")\n",
    "    \n",
    "    # 评估当前种群的适应度\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    # 记录最佳适应度\n",
    "    fitnesses_plot.append(max(fitnesses)[0])\n",
    "\n",
    "    # 选择下一代个体\n",
    "    offspring = toolbox.select(population, len(population)-ELITE_SIZE)\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # 找到精英个体\n",
    "    elites = tools.selBest(population, ELITE_SIZE)\n",
    "\n",
    "    # 交叉与变异操作\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        # 检查个体长度\n",
    "        if len(child1) > 1 and len(child2) > 1:  # 确保个体长度大于1\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # 评估新个体的适应度\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # 替换种群\n",
    "    population[:] = elites + offspring\n",
    "\n",
    "# 找出最优个体及其超参数\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "print(f\"Best individual is {best_ind}, with fitness {best_ind.fitness.values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best individual is [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0], with fitness (0.8916666666666666,)\n",
      "Best n_estimators: 37\n",
      "Best max_depth: 48\n",
      "Best min_samples_split: 3\n",
      "Best max_features: 0.95\n",
      "Test accuracy: 0.89375\n"
     ]
    }
   ],
   "source": [
    "# 找出最优个体及其超参数\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "print(f\"Best individual is {best_ind}, with fitness {best_ind.fitness.values}\")\n",
    "\n",
    "best_n_estimators = gray_decode(best_ind[0:7])  # 解码n_estimators\n",
    "best_max_depth = gray_decode(best_ind[7:13])  # 解码max_depth\n",
    "best_min_samples_split = gray_decode(best_ind[13:18])  # 解码min_samples_split\n",
    "best_max_features = gray_decode(best_ind[18:26]) / X.shape[1]  # 解码max_features\n",
    "\n",
    "print(f\"Best n_estimators: {best_n_estimators}\")\n",
    "print(f\"Best max_depth: {best_max_depth}\")\n",
    "print(f\"Best min_samples_split: {best_min_samples_split}\")\n",
    "print(f\"Best max_features: {best_max_features}\")\n",
    "\n",
    "# 用最优超参数训练最终模型\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=best_n_estimators,\n",
    "    max_depth=best_max_depth if best_max_depth > 0 else None,\n",
    "    min_samples_split=int(best_min_samples_split) if best_min_samples_split >= 2 else 2,\n",
    "    max_features=int(best_max_features) if best_max_features >= 1 else float(best_max_features),\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据文件并进行预测\n",
    "X_test = pd.read_csv('mobile-phone-test-no-price-range.csv',index_col=0)\n",
    "best_rf.fit(X, y)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# 将预测结果写入文件\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "pd.Series(y_pred, name='price_range').to_csv('RF-GA_mobile-phone-test-predictions.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF-PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyswarms.single import GlobalBestPSO\n",
    "# 关闭warning,ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集,mobile-phone-train.csv\n",
    "data = pd.read_csv('mobile-phone-train.csv',index_col=0)\n",
    "#data.iloc[:,:-1]\n",
    "X, y = data.iloc[:,:-1], data['price_range']\n",
    "# 对y进行label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=55, max_features=0.95, n_estimators=120,\n",
       "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=55, max_features=0.95, n_estimators=120,\n",
       "                       random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=55, max_features=0.95, n_estimators=120,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义适应度函数\n",
    "def evaluate_rf(params):\n",
    "    #n_estimators, max_depth, min_samples_split, max_features = params\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_split = params[2]\n",
    "    max_features = params[3]\n",
    "\n",
    "    # 参数合法性检查，将非法参数转换为合理范围\n",
    "    n_estimators = max(1, int(n_estimators))  # 保证 n_estimators 至少为 1\n",
    "    max_depth = int(max_depth) if int(max_depth) > 0 else None  # 保证 max_depth 大于 0 或为 None\n",
    "    min_samples_split = max(2, int(min_samples_split))  # 最小分裂样本数不能小于 2\n",
    "\n",
    "    # max_features 校正，确保为有效值\n",
    "    if max_features <= 0:\n",
    "        max_features = None  # 默认使用所有特征\n",
    "    elif max_features <= 1:\n",
    "        max_features = float(max_features)  # 如果 max_features 小于等于 1，作为比例处理\n",
    "    else:\n",
    "        max_features = int(max_features)  # 否则作为整数处理\n",
    "    # 定义 MLPClassifier 模型\n",
    "    \n",
    "    # 定义 RandomForestClassifier 模型\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, \n",
    "        max_depth=max_depth, \n",
    "        min_samples_split=min_samples_split, \n",
    "        max_features=max_features,  # 调整后的 max_features\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # 使用交叉验证评估模型的 F1 宏平均分数\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='f1_macro')\n",
    "    return -np.mean(scores)  # PSO 是最小化问题，返回负值以最大化得分\n",
    "\n",
    "def evaluate_mlp_batch(params):\n",
    "    # 用于批量处理的适应度函数\n",
    "    return np.array([evaluate_rf(param) for param in params])\n",
    "\n",
    "# 定义参数的边界和限制\n",
    "lb = [100, 2, 2, 0.001]  # 各参数的最小值: [n_estimators, max_depth, min_samples_split, max_features]\n",
    "ub = [500, 50, 20, X.shape[1]]  # 各参数的最大值: [n_estimators, max_depth, min_samples_split, max_features]\n",
    "dimensions = len(lb)  # 超参数维度\n",
    "\n",
    "# 初始化 PSO\n",
    "optimizer = GlobalBestPSO(n_particles=20, dimensions=dimensions, options={'c1': 0.5, 'c2': 0.3, 'w': 0.9}, bounds=(lb, ub))\n",
    "best_cost, best_pos = optimizer.optimize(evaluate_mlp_batch, iters=50)\n",
    "\n",
    "# 输出最优参数和对应的得分\n",
    "print(\"Best Parameters: \", best_pos)\n",
    "print(\"Best Score (negative F1 Macro): \", best_cost)\n",
    "\n",
    "# 使用最优参数训练模型并在测试集上评估\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=int(best_pos[0]),\n",
    "    max_depth=int(best_pos[1]) if int(best_pos[1]) > 0 else None,\n",
    "    min_samples_split=int(best_pos[2]),\n",
    "    max_features=int(best_pos[3]) if int(best_pos[3]) >= 1 else float(best_pos[3]),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据文件并进行预测\n",
    "X_test = pd.read_csv('mobile-phone-test-no-price-range.csv',index_col=0)\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# 将预测结果写入文件\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "pd.Series(y_pred, name='price_range').to_csv('RF-PSO_mobile-phone-test-predictions.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP\n",
    "## MLP-GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyswarms.single import GlobalBestPSO\n",
    "# 关闭warning,ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 加载数据集,mobile-phone-train.csv\n",
    "data = pd.read_csv('mobile-phone-train.csv',index_col=0)\n",
    "#data.iloc[:,:-1]\n",
    "X, y = data.iloc[:,:-1], data['price_range']\n",
    "# 对y进行label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义适应度函数\n",
    "def evaluate_mlp(individual):\n",
    "    # 个体包含的超参数\n",
    "    hidden_layer_sizes, activation, solver, alpha, learning_rate_init = individual\n",
    "\n",
    "    # 将参数从列表形式转换为对应类型，限制 hidden_layer_sizes 为正整数\n",
    "    hidden_layer_sizes = tuple([max(1, int(hidden_layer_sizes))])  # 隐藏层大小，确保大于0\n",
    "    activation = ['identity', 'logistic', 'tanh', 'relu'][int(min(max(activation, 0), 3))]  # 激活函数\n",
    "    solver = ['lbfgs', 'sgd', 'adam'][int(min(max(solver, 0), 2))]  # 优化算法\n",
    "    alpha = max(0.0001, float(alpha))  # L2 正则化\n",
    "    learning_rate_init = max(0.0001, float(learning_rate_init))  # 初始学习率\n",
    "\n",
    "    # 定义 MLPClassifier 模型\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                          activation=activation,\n",
    "                          solver=solver,\n",
    "                          alpha=alpha,\n",
    "                          learning_rate_init=learning_rate_init,\n",
    "                          random_state=42,\n",
    "                          max_iter=200)\n",
    "\n",
    "    # 使用交叉验证评估模型的 F1 宏平均分数\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='f1_macro')\n",
    "    return (np.mean(scores),)\n",
    "\n",
    "# 初始化超参数的取值范围\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"hidden_layer_sizes\", random.randint, 10, 100)  # 隐藏层大小\n",
    "toolbox.register(\"activation\", random.randint, 0, 3)  # 激活函数索引（0:identity, 1:logistic, 2:tanh, 3:relu）\n",
    "toolbox.register(\"solver\", random.randint, 0, 2)  # 优化算法索引（0:lbfgs, 1:sgd, 2:adam）\n",
    "toolbox.register(\"alpha\", random.uniform, 0.0001, 0.1)  # L2 正则化\n",
    "toolbox.register(\"learning_rate_init\", random.uniform, 0.0001, 0.1)  # 初始学习率\n",
    "\n",
    "# 创建个体（包含超参数）\n",
    "toolbox.register(\"individual\", tools.initCycle, creator.Individual,\n",
    "                 (toolbox.hidden_layer_sizes, toolbox.activation, toolbox.solver, toolbox.alpha, toolbox.learning_rate_init))\n",
    "\n",
    "# 创建种群\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# 注册操作\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)  # 交叉操作\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)  # 变异操作\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)  # 选择操作\n",
    "toolbox.register(\"evaluate\", evaluate_mlp)  # 适应度评估\n",
    "\n",
    "# 进化参数设置\n",
    "population = toolbox.population(n=50)  # 种群数量\n",
    "NGEN = 20  # 迭代次数\n",
    "CXPB = 0.5  # 交叉概率\n",
    "MUTPB = 0.2  # 变异概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.04570116958891931,\n",
       "              hidden_layer_sizes=84, learning_rate_init=0.07123981428301314,\n",
       "              random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, alpha=0.04570116958891931,\n",
       "              hidden_layer_sizes=84, learning_rate_init=0.07123981428301314,\n",
       "              random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=0.04570116958891931,\n",
       "              hidden_layer_sizes=84, learning_rate_init=0.07123981428301314,\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 执行遗传算法优化\n",
    "for gen in range(NGEN):\n",
    "    print(f\"Generation {gen}\")\n",
    "    \n",
    "    # 评估当前种群的适应度\n",
    "    fitnesses = list(map(toolbox.evaluate, population))\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # 选择下一代个体\n",
    "    offspring = toolbox.select(population, len(population))\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "    # 交叉与变异操作\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1, child2)\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "\n",
    "    # 评估新个体的适应度\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # 替换种群\n",
    "    population[:] = offspring\n",
    "\n",
    "# 找出最优个体及其超参数\n",
    "best_ind = tools.selBest(population, 1)[0]\n",
    "\n",
    "# 用最优超参数训练最终模型\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(max(1,int(best_ind[0])),),\n",
    "    activation=['identity', 'logistic', 'tanh', 'relu'][int(best_ind[1])],\n",
    "    solver=['lbfgs', 'sgd', 'adam'][int(best_ind[2])],\n",
    "    alpha=float(best_ind[3]),\n",
    "    learning_rate_init=float(best_ind[4]),\n",
    "    random_state=42,\n",
    "    max_iter=200\n",
    ")\n",
    "best_mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据文件并进行预测\n",
    "X_test = pd.read_csv('mobile-phone-test-no-price-range.csv',index_col=0)\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# 将预测结果写入文件\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "pd.Series(y_pred, name='price_range').to_csv('GA-MLP_mobile-phone-test-predictions.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyswarms.single import GlobalBestPSO\n",
    "# 关闭warning,ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# 加载数据集,mobile-phone-train.csv\n",
    "data = pd.read_csv('mobile-phone-train.csv',index_col=0)\n",
    "#data.iloc[:,:-1]\n",
    "X, y = data.iloc[:,:-1], data['price_range']\n",
    "# 对y进行label encoding\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;identity&#x27;, alpha=0.000847007346,\n",
       "              hidden_layer_sizes=33, learning_rate_init=0.0736730179,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;identity&#x27;, alpha=0.000847007346,\n",
       "              hidden_layer_sizes=33, learning_rate_init=0.0736730179,\n",
       "              random_state=42, solver=&#x27;lbfgs&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='identity', alpha=0.000847007346,\n",
       "              hidden_layer_sizes=33, learning_rate_init=0.0736730179,\n",
       "              random_state=42, solver='lbfgs')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 适应度函数\n",
    "def evaluate_mlp(params):\n",
    "    # 将 params 转换为适合 MLP 的形状\n",
    "    hidden_layer_sizes = (int(params[0]),)  # 隐藏层大小\n",
    "    '''activation = 'relu' if params[1] < 0.5 else 'tanh'  # 激活函数\n",
    "    solver = 'adam' if params[2] < 0.5 else 'sgd'  # 优化器'''\n",
    "    activation = ['identity', 'logistic', 'tanh', 'relu'][int(params[1])]  # 激活函数\n",
    "    solver = ['lbfgs', 'sgd', 'adam'][int(params[2])]  # 优化算法\n",
    "    alpha = params[3]  # L2 正则化\n",
    "    learning_rate_init = params[4]  # 初始学习率\n",
    "\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes,\n",
    "                          activation=activation,\n",
    "                          solver=solver,\n",
    "                          alpha=alpha,\n",
    "                          random_state=42,\n",
    "                          learning_rate_init=learning_rate_init,\n",
    "                          max_iter=200)\n",
    "\n",
    "    # 交叉验证的平均得分（F1宏平均）\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_macro')\n",
    "    return -np.mean(scores)  # 返回负值，因为 PSO 寻找最小值\n",
    "\n",
    "def evaluate_mlp_batch(params):\n",
    "    # 用于批量处理的适应度函数\n",
    "    return np.array([evaluate_mlp(param) for param in params])\n",
    "\n",
    "# PSO 参数\n",
    "lb = [10, 0, 0, 0.0001, 0.0001]  # 各参数的最小值: [隐藏层大小, 激活函数索引, 优化算法索引, alpha, learning_rate_init]\n",
    "ub = [100, 3, 2, 0.1, 0.1]  # 各参数的最大值: [隐藏层大小, 激活函数索引, 优化算法索引, alpha, learning_rate_init]\n",
    "dimensions = len(lb)  # 超参数维度\n",
    "\n",
    "# 初始化 PSO\n",
    "optimizer = GlobalBestPSO(n_particles=20, dimensions=dimensions, options={'c1': 0.5, 'c2': 0.3, 'w': 0.9}, bounds=(lb, ub))\n",
    "# 用于记录每次迭代的信息\n",
    "best_fitness_list = []\n",
    "average_fitness_list = []\n",
    "iteration_times = []\n",
    "\n",
    "# 运行 PSO 优化\n",
    "start_time = time.time()  # 开始计时\n",
    "best_cost, best_pos = optimizer.optimize(evaluate_mlp_batch, iters=50)\n",
    "\n",
    "# 在测试集上验证\n",
    "hidden_layer_sizes = int(best_pos[0])\n",
    "activation = ['identity', 'logistic', 'tanh', 'relu'][int(best_pos[1])]\n",
    "solver = ['lbfgs', 'sgd', 'adam'][int(best_pos[2])]\n",
    "alpha = best_pos[3]\n",
    "learning_rate_init = best_pos[4]\n",
    "\n",
    "best_mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(hidden_layer_sizes,),\n",
    "    activation=activation,\n",
    "    solver=solver,\n",
    "    alpha=alpha,\n",
    "    learning_rate_init=learning_rate_init,\n",
    "    max_iter=200,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_mlp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试数据文件并进行预测\n",
    "X_test = pd.read_csv('mobile-phone-test-no-price-range.csv',index_col=0)\n",
    "# 标准化数据\n",
    "scaler = StandardScaler()\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "y_pred = best_mlp.predict(X_test)\n",
    "\n",
    "# 将预测结果写入文件\n",
    "y_pred = le.inverse_transform(y_pred)\n",
    "pd.Series(y_pred, name='price_range').to_csv('MLP-PSO_mobile-phone-test-predictions.csv', header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
